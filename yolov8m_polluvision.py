# -*- coding: utf-8 -*-
"""YOLOv8m_PolluVision.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xTCfS-hfUPBRZqtDHECpRnW578TqkSKs

# PolluVision Project - YOLOv8 Medium
---------------------------------------------

##1. Install Ultralytics using pip
"""

!pip install ultralytics

"""___________________________________
##2. Imports Necessary Libraries
"""

from ultralytics import YOLO
import os
from IPython.display import display, Image
from IPython import display

!yolo checks

"""------------------------
##3. Import the Dataset from Roboflow Website
"""

# Import Roboflow to use the dataset
!pip install roboflow
from roboflow import Roboflow
rf = Roboflow(api_key="wBhhcFexJ3QDDrx6zu0d")
project = rf.workspace("sdaia-xqoon").project("capstone-avmph")
dataset = project.version(8).download("yolov8")

"""-------------
## 4. Model Train
Uses the `!yolo` command-line interface to execute YOLO for object detection. Here's a breakdown of the parameters used:

- `task=detect`: Specifies the task as object detection.
- `mode=train`: Runs the detection in the training mode.
- `model=yolov8m.pt`: Uses the YOLOv8m model for detection.
- `data=/content/Capstone-8/data.yaml`: Specifies the data configuration file path.
- `epochs=100`: Sets the number of training epochs to 100.
- `imgsz=640`: Defines the input image size as 640x640 pixels.
- `conf=0.45`: Sets the confidence threshold to 0.45 for object detection.
- `iou=0.4`: Sets the IoU (Intersection over Union) threshold to 0.4 for object detection.

This command will execute YOLOv8m for object detection based on the specified configurations and parameters. Adjustments to these parameters can affect the model's performance and accuracy in detecting objects within images.

"""

# Command to run YOLO for object detection
!yolo task=detect mode=train model= yolov8m.pt data= /content/Capstone-8/data.yaml epochs=100 imgsz=640 conf =0.45 iou= 0.4

"""---
## 5. Model Validation

Explanation of the code:

1. `path_best_weights="/content/runs/detect/train2/weights/best.pt"`: This line defines the variable `path_best_weights` with the path to the best weights of the YOLO model. This file likely contains the learned parameters that achieved the best performance during training.

2. `model = YOLO(path_best_weights)`: Creates an instance of the YOLO object and loads the YOLO model using the specified best weights file located at `path_best_weights`.

3. `model.val()`: Invokes the `val()` method on the `model` object. The `val()` method is likely used for validation or evaluation of the model's performance on a validation dataset. This step evaluates the model's accuracy, precision, or other performance metrics using the loaded best weights.

This code snippet demonstrates the process of initializing a YOLO model object with pre-trained weights and performing a validation step to assess the model's performance using those weights. Adjustments or enhancements to the validation process may involve modifications to the `val()` method depending on the specific implementation within the `YOLO` class.

"""

# Define the path to the best weights of the YOLO model
path_best_weights="/content/runs/detect/train2/weights/best.pt"

# Create a YOLO object and load the model with the best weights
model = YOLO(path_best_weights)

# Perform validation using the loaded model
model.val()

"""----
##6. Model Prediction

Explanation of the parameters used in the command:

- `task=detect`: Specifies the task as object detection.
- `mode=predict`: Runs the detection in prediction mode.
- `model=/content/runs/detect/train2/weights/best.pt`: Specifies the path of the trained model weights for the prediction.
- `source=/content/Capstone-8/test/images`: Sets the source directory where images for prediction are located.
- `conf=0.45`: Sets the confidence threshold to 0.45 for object detection.

This command executes YOLO in prediction mode using a specific trained model (`best.pt`) located in the specified directory. It runs object detection on images located in the `/content/Capstone-8/test/images` directory and sets the confidence threshold for object detection to 0.45. Adjusting the confidence threshold might affect the number of detected objects based on their confidence scores.

"""

# Command to run YOLO for object detection prediction
!yolo task=detect mode=predict model=/content/runs/detect/train2/weights/best.pt source= /content/Capstone-8/test/images conf=0.45

"""---
## 7. Importing necessary libraries for image processing and visualization

"""

# Commented out IPython magic to ensure Python compatibility.
# OpenCV for computer vision tasks and image processing
import cv2 as cv

# Operating system module for file and directory handling
import os

# Random module for generating random numbers and performing random operations
import random

# Matplotlib's image module for working with images
import matplotlib.image as mpimg

# Seaborn for data visualization, setting the style to 'darkgrid'
import seaborn as sns
sns.set_style('darkgrid')

# Magic command for inline plotting in Jupyter Notebooks
# %matplotlib inline

# Python Imaging Library (PIL) for image manipulation
from PIL import Image

# Matplotlib for plotting and visualization
import matplotlib.pyplot as plt
# %matplotlib inline

"""### 7.1. Plots the train and validation losses for box and class predictions across epochs."""

# Pandas for data manipulation and analysis
import pandas as pd

# Reading the results CSV file containing training/validation losses
result = pd.read_csv('/content/runs/detect/train2/results.csv')

# Displaying the first few rows of the loaded CSV data
result.head()

# Stripping whitespace from column names for consistency
result.columns = result.columns.str.strip()

# Extracting necessary columns for plotting
epoch_column = result['epoch']
box_train_losses = result['train/box_loss']
box_val_losses = result['val/box_loss']
cls_train_losses = result['train/cls_loss']
cls_val_losses = result['val/cls_loss']


# Plotting the train and validation losses
plt.figure(figsize=(12,5))
plt.style.use('ggplot')  # Choosing a style for the plot (you can use a different style)
plt.subplot(1,2,1)
plt.plot(epoch_column, box_train_losses, label='train_losses')
plt.plot(epoch_column, box_val_losses, label='val_losses')
plt.grid(True, linestyle='--', linewidth=0.5, color='gray') # Adding a grid
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Train and Validation Box Losses')
plt.legend()

plt.subplot(1,2,2)
plt.plot(epoch_column, cls_train_losses, label='train_losses')
plt.plot(epoch_column, cls_val_losses, label='val_losses')
plt.grid(True, linestyle='--', linewidth=0.5, color='gray') # Adding a grid
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Train and Validation Class Losses')
plt.legend()
plt.show()

"""### 7.2. Reading and displaying an images"""

# Read an image using OpenCV from the specified file path
img = cv.imread("/content/runs/detect/train2/val_batch1_labels.jpg")

# Convert the color space of the image from BGR to RGB
img_cvt=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)
#gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)

# Set the figure size
plt.figure(figsize=(15, 15))

# Display the image
plt.imshow(img_cvt)

img = cv.imread("/content/runs/detect/train2/train_batch1.jpg")
img_cvt=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)
#gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)
plt.figure(figsize=(15, 15))
plt.imshow(img_cvt)

"""### 7.3. Visualize the Predicted Images"""

# pollu_detect function takes the path to an image file as an argument and performs pollution detection using a pre-trained model.
def pollu_detect(img_path):

    # Read the image
    img = cv2.imread(img_path)

    # Pass the image through the detection model and get the result
    detect_result = model(img)

    # Plot the detections
    detect_img = detect_result[0].plot()

    # Convert the image to RGB format
    detect_img = cv2.cvtColor(detect_img, cv2.COLOR_BGR2RGB)

    return detect_img

# Iterates over the images, loads each image, performs pollution detection using `pollu_detect()`, and displays the detected images on the corresponding subplots.

import random

#Define the directory where the custom images are stored
custom_image_dir = '/content/Capstone-8/test/images'

#Get the list of image files in the directory
image_files = os.listdir(custom_image_dir)

#Select 16 random images from the list
selected_images = random.sample(image_files, 16)

#Create a figure with subplots for each image
fig, axes = plt.subplots(nrows=4, ncols=4, figsize=(15, 15))

#Iterate over the selected images and plot each one
for i, img_file in enumerate(selected_images):

    # Compute the row and column index of the current subplot
    row_idx = i // 4
    col_idx = i % 4

    # Load the current image and run object detection
    img_path = os.path.join(custom_image_dir, img_file)
    detect_img = pollu_detect(img_path)

    # Plot the current image on the appropriate subplot
    axes[row_idx, col_idx].imshow(detect_img)
    axes[row_idx, col_idx].axis('off')

#Adjust the spacing between the subplots
plt.subplots_adjust(wspace=0.05, hspace=0.05)